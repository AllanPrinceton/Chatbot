{https://colab.research.google.com/drive/1rvk8VNb9k6jXqe13H8LxvtptG3A-rHt3#scrollTo=5gN60BM3Eklp&uniqifier=2}
{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taLA3ABYef5v","executionInfo":{"status":"ok","timestamp":1677696138249,"user_tz":-240,"elapsed":3808,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}},"outputId":"0e4983da-c8a2-4209-c167-92c1f05022de"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Chatbot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cG_OM8FUefva","executionInfo":{"status":"ok","timestamp":1677696138249,"user_tz":-240,"elapsed":15,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}},"outputId":"26a7b92b-eebd-4873-8356-e99217ab5e86"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Chatbot\n"]}]},{"cell_type":"code","source":["! git clone https://github.com/AllanPrinceton/Chatbot.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5LQoRhFefhV","executionInfo":{"status":"ok","timestamp":1677696138250,"user_tz":-240,"elapsed":11,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}},"outputId":"39e5d122-b7bc-47d6-f92d-f45c27ce885d"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Chatbot' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Chatbot/Chatbot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DG5rH9kHefNJ","executionInfo":{"status":"ok","timestamp":1677696138250,"user_tz":-240,"elapsed":8,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}},"outputId":"ba6cd309-c08e-460b-eb63-bc8678b0363d"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Chatbot/Chatbot\n"]}]},{"cell_type":"code","source":["!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwdbaS3ten_C","executionInfo":{"status":"ok","timestamp":1677696138849,"user_tz":-240,"elapsed":14,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}},"outputId":"a3b74715-972c-4e67-b362-94c381dcd9e3"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}]},{"cell_type":"code","execution_count":115,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677696139261,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"},"user_tz":-240},"id":"V6M36gq1Ec-4"},"outputs":[],"source":["# import necessary libraries\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","import json\n","import pickle\n","\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD\n","from keras.optimizers import gradient_descent_v2\n","import random\n","from keras.models import load_model\n","\n","# create an object of WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# importing the GL Bot corpus file for pre-processing\n","\n","words=[]\n","classes = []\n","documents = []\n","ignore_words = ['?', '!']\n","data_file = open(\"trainingbot.json\").read()\n","intents = json.loads(data_file)"]},{"cell_type":"code","execution_count":116,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1677696151244,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"},"user_tz":-240},"id":"Yo6yIrftEgmG","outputId":"5ec6eccb-ed57-4c67-c89d-7a9fe363bb74"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","\n","        #tokenize each word\n","        w = nltk.word_tokenize(pattern)\n","        words.extend(w)\n","        #add documents in the corpus\n","        documents.append((w, intent['tag']))\n","\n","        # add to our classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"]},{"cell_type":"code","execution_count":117,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1013,"status":"ok","timestamp":1677696154728,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"},"user_tz":-240},"id":"5gN60BM3Eklp","outputId":"babd4e03-f342-4756-a42f-5970fd3e95ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["128 documents\n","8 classes ['Bot', 'Exit', 'Intro', 'NN', 'Olympus', 'Profane', 'SL', 'Ticket']\n","158 unique lemmatized words ['a', 'able', 'access', 'activation', 'ada', 'adam', 'aifl', 'aiml', 'am', 'an', 'ann', 'anyone', 'are', 'artificial', 'backward', 'bad', 'bagging', 'batch', 'bayes', 'belong', 'best', 'blended', 'bloody', 'boosting', 'bot', 'buddy', 'classification', 'contact', 'create', 'cross', 'cya', 'day', 'deep', 'did', 'diffult', 'do', 'ensemble', 'epoch', 'explain', 'first', 'for', 'forest', 'forward', 'from', 'function', 'good', 'goodbye', 'gradient', 'great', 'hate', 'have', 'hell', 'hello', 'help', 'helped', 'hey', 'hi', 'hidden', 'hour', 'how', 'hyper', 'i', 'imputer', 'in', 'intelligence', 'is', 'jerk', 'joke', 'knn', 'later', 'layer', 'learner', 'learning', 'leaving', 'link', 'listen', 'logistic', 'lot', 'machine', 'me', 'ml', 'my', 'naive', 'name', 'nb', 'net', 'network', 'neural', 'no', 'not', 'of', 'olympus', 'olypus', 'on', 'online', 'operation', 'opertions', 'otimizer', 'parameter', 'piece', 'please', 'pm', 'problem', 'propagation', 'random', 'regression', 'relu', 'screw', 'see', 'sgd', 'shit', 'sigmoid', 'sl', 'smart', 'softmax', 'solution', 'solved', 'stupid', 'supervised', 'svm', 'talking', 'teach', 'techb=niques', 'technique', 'thank', 'thanks', 'the', 'there', 'think', 'ticket', 'time', 'to', 'ton', 'too', 'tool', 'unable', 'understand', 'up', 'use', 'useless', 'validation', 'very', 'visible', 'wasted', 'weight', 'what', 'whats', 'when', 'who', 'whom', 'window', 'with', 'work', 'working', 'ya', 'yo', 'you', 'your']\n"]}],"source":["# lemmatize, lower each word and remove duplicates\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","\n","# sort classes\n","classes = sorted(list(set(classes)))\n","\n","# documents = combination between patterns and intents\n","print (len(documents), \"documents\")\n","\n","# classes = intents\n","print (len(classes), \"classes\", classes)\n","\n","# words = all words, vocabulary\n","print (len(words), \"unique lemmatized words\", words)\n","\n","# creating a pickle file to store the Python objects which we will use while predicting\n","pickle.dump(words,open('words.pkl','wb')) \n","pickle.dump(classes,open('classes.pkl','wb'))"]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677696156993,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"},"user_tz":-240},"id":"Y0J2tZn1NSbu","outputId":"b1e0f82e-0095-4f5f-ae96-1b427376ef4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data created\n"]}],"source":["training = []\n","\n","# create an empty array for our output\n","output_empty = [0] * len(classes)\n","\n","# training set, bag of words for each sentence\n","for doc in documents:\n","    # initialize our bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","   \n","    # lemmatize each word - create base word, in attempt to represent related words\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","    \n","    # create our bag of words array with 1, if word match found in current pattern\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","    # output is a '0' for each tag and '1' for current tag (for each pattern)\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","    training.append([bag, output_row])\n","\n","# shuffle features and converting it into numpy arrays\n","random.shuffle(training)\n","training = np.array(training)\n","\n","# create train and test lists\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","\n","print(\"Training data created\")"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21473,"status":"ok","timestamp":1677696181014,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"},"user_tz":-240},"id":"txzNGx1WPxAb","outputId":"42833594-322e-49a2-e2f4-41ede5462ab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","26/26 [==============================] - 1s 2ms/step - loss: 2.0598 - accuracy: 0.2188 \n","Epoch 2/200\n","26/26 [==============================] - 0s 3ms/step - loss: 1.9517 - accuracy: 0.2266\n","Epoch 3/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.8878 - accuracy: 0.2812\n","Epoch 4/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.8113 - accuracy: 0.3047\n","Epoch 5/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.7285 - accuracy: 0.3672\n","Epoch 6/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.6258 - accuracy: 0.4375\n","Epoch 7/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.5666 - accuracy: 0.4766\n","Epoch 8/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.4796 - accuracy: 0.4453\n","Epoch 9/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.3943 - accuracy: 0.4688\n","Epoch 10/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.1546 - accuracy: 0.5938\n","Epoch 11/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.0850 - accuracy: 0.6562\n","Epoch 12/200\n","26/26 [==============================] - 0s 2ms/step - loss: 1.0889 - accuracy: 0.6094\n","Epoch 13/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.8641 - accuracy: 0.7344\n","Epoch 14/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.7752 - accuracy: 0.7656\n","Epoch 15/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.8256 - accuracy: 0.7109\n","Epoch 16/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.8359\n","Epoch 17/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7969\n","Epoch 18/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.7891\n","Epoch 19/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8359\n","Epoch 20/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8906\n","Epoch 21/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8828\n","Epoch 22/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8828\n","Epoch 23/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.9141\n","Epoch 24/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.9453\n","Epoch 25/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.9062\n","Epoch 26/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9219\n","Epoch 27/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9062\n","Epoch 28/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9766\n","Epoch 29/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9609\n","Epoch 30/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.9609\n","Epoch 31/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9297\n","Epoch 32/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9766\n","Epoch 33/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9531\n","Epoch 34/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9766\n","Epoch 35/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9922\n","Epoch 36/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9844\n","Epoch 37/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9688\n","Epoch 38/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9844\n","Epoch 39/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9922\n","Epoch 40/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9766\n","Epoch 41/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9766\n","Epoch 42/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9609\n","Epoch 43/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9688\n","Epoch 44/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 1.0000\n","Epoch 45/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9844\n","Epoch 46/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9609\n","Epoch 47/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 1.0000\n","Epoch 48/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9922\n","Epoch 49/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9844\n","Epoch 50/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9844\n","Epoch 51/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9453\n","Epoch 52/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9688\n","Epoch 53/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9609\n","Epoch 54/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9766\n","Epoch 55/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9922\n","Epoch 56/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9922\n","Epoch 57/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9844\n","Epoch 58/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 1.0000\n","Epoch 59/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9922\n","Epoch 60/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 1.0000\n","Epoch 61/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9766\n","Epoch 62/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9844\n","Epoch 63/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9844\n","Epoch 64/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9922\n","Epoch 65/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9766\n","Epoch 66/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 1.0000\n","Epoch 67/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9922\n","Epoch 68/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000\n","Epoch 69/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9844\n","Epoch 70/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9688\n","Epoch 71/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9922\n","Epoch 72/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9844\n","Epoch 73/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000\n","Epoch 74/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9844\n","Epoch 75/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9922\n","Epoch 76/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9922\n","Epoch 77/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n","Epoch 78/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9922\n","Epoch 79/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n","Epoch 80/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9922\n","Epoch 81/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9922\n","Epoch 82/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9766\n","Epoch 83/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n","Epoch 84/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9766\n","Epoch 85/200\n","26/26 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9922\n","Epoch 86/200\n","26/26 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9922\n","Epoch 87/200\n","26/26 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9922\n","Epoch 88/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n","Epoch 89/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9922\n","Epoch 90/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9922\n","Epoch 91/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n","Epoch 92/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9922\n","Epoch 93/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000\n","Epoch 94/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9922\n","Epoch 95/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9844\n","Epoch 96/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9844\n","Epoch 97/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9922\n","Epoch 98/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000\n","Epoch 99/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9922\n","Epoch 100/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9922\n","Epoch 101/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9922\n","Epoch 102/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 103/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9766\n","Epoch 104/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9844\n","Epoch 105/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9922\n","Epoch 106/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9844\n","Epoch 107/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 108/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n","Epoch 109/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n","Epoch 110/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9922\n","Epoch 111/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9922\n","Epoch 112/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9922\n","Epoch 113/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n","Epoch 114/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n","Epoch 115/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000\n","Epoch 116/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 1.0000\n","Epoch 117/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n","Epoch 118/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 119/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9844\n","Epoch 120/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n","Epoch 121/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 122/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n","Epoch 123/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9844\n","Epoch 124/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n","Epoch 125/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9844\n","Epoch 126/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9922\n","Epoch 127/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n","Epoch 128/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9922\n","Epoch 129/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n","Epoch 130/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n","Epoch 131/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n","Epoch 132/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n","Epoch 133/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9922\n","Epoch 134/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n","Epoch 135/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n","Epoch 136/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9922\n","Epoch 137/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9844\n","Epoch 138/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n","Epoch 139/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n","Epoch 140/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n","Epoch 141/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9922\n","Epoch 142/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 143/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 144/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 145/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n","Epoch 146/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n","Epoch 147/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9922\n","Epoch 148/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n","Epoch 149/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 150/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9844\n","Epoch 151/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n","Epoch 152/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n","Epoch 153/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n","Epoch 154/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9922\n","Epoch 155/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9922\n","Epoch 156/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9844\n","Epoch 157/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9922\n","Epoch 158/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9844\n","Epoch 159/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n","Epoch 160/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9922\n","Epoch 161/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n","Epoch 162/200\n","26/26 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9922\n","Epoch 163/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9844\n","Epoch 164/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n","Epoch 165/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9922\n","Epoch 166/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n","Epoch 167/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 1.0000\n","Epoch 168/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n","Epoch 169/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n","Epoch 170/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9922\n","Epoch 171/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n","Epoch 172/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9922\n","Epoch 173/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n","Epoch 174/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n","Epoch 175/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9844\n","Epoch 176/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9922\n","Epoch 177/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 178/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n","Epoch 179/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 180/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n","Epoch 181/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9922\n","Epoch 182/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 183/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000\n","Epoch 184/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9922\n","Epoch 185/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 186/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n","Epoch 187/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9922\n","Epoch 188/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9922\n","Epoch 189/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9922\n","Epoch 190/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n","Epoch 191/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n","Epoch 192/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000\n","Epoch 193/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 194/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 195/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n","Epoch 196/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9922\n","Epoch 197/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n","Epoch 198/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 199/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9922\n","Epoch 200/200\n","26/26 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n","\n","\n","**************************************************\n","\n","Model Created Successfully!\n"]}],"source":["model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n","sgd = gradient_descent_v2.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#fitting and saving the model \n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('chatbot.h5', hist) # we will pickle this model to use in the future\n","print(\"\\n\")\n","print(\"*\"*50)\n","print(\"\\nModel Created Successfully!\")"]},{"cell_type":"code","execution_count":120,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1677696181015,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"},"user_tz":-240},"id":"ZC02HbsbRaFo"},"outputs":[],"source":["# load the saved model file\n","model = load_model('chatbot.h5')\n","intents = json.loads(open(\"trainingbot.json\").read())\n","words = pickle.load(open('words.pkl','rb'))\n","classes = pickle.load(open('classes.pkl','rb'))"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"NZWLC4WfRbKK","executionInfo":{"status":"ok","timestamp":1677696181016,"user_tz":-240,"elapsed":30,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}}},"outputs":[],"source":["def clean_up_sentence(sentence):\n","\n","    # tokenize the pattern - split words into array\n","    sentence_words = nltk.word_tokenize(sentence)\n","    \n","    # stem each word - create short form for word\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","\n","\n","# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","\n","def bow(sentence, words, show_details=True):\n","\n","    # tokenize the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","\n","    # bag of words - matrix of N words, vocabulary matrix\n","    bag = [0]*len(words) \n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s: \n","               \n","                # assign 1 if current word is in the vocabulary position\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n","\n","def predict_class(sentence, model):\n","   \n","    # filter out predictions below a threshold\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    error = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>error]\n","    \n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    \n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"N5UjQB3URpvB","executionInfo":{"status":"ok","timestamp":1677696181017,"user_tz":-240,"elapsed":29,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}}},"outputs":[],"source":["# function to get the response from the model\n","\n","def getResponse(ints, intents_json):\n","    tag = ints[0]['intent']\n","    list_of_intents = intents_json['intents']\n","    for i in list_of_intents:\n","        if(i['tag']== tag):\n","            result = random.choice(i['responses'])\n","            break\n","    return result\n","\n","# function to predict the class and get the response\n","\n","def chatbot_response(text):\n","    ints = predict_class(text, model)\n","    res = getResponse(ints, intents)\n","    return res"]},{"cell_type":"code","execution_count":123,"metadata":{"id":"ZGM8wCRYRsu8","executionInfo":{"status":"ok","timestamp":1677696181017,"user_tz":-240,"elapsed":28,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}}},"outputs":[],"source":["def start_chat():\n","    print(\"Bot: This is Sophie! Your Personal Assistant.\\n\\n\")\n","    while True:\n","        inp = str(input()).lower()\n","        if inp.lower()==\"end\":\n","            break\n","        if inp.lower()== '' or inp.lower()== '*':\n","            print('Please re-phrase your query!')\n","            print(\"-\"*50)\n","        else:\n","            print(f\"Bot: {chatbot_response(inp)}\"+'\\n')\n","            print(\"-\"*50)"]},{"cell_type":"code","execution_count":124,"metadata":{"id":"ykUtQ23HbD6s","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"error","timestamp":1677696181018,"user_tz":-240,"elapsed":28,"user":{"displayName":"Allan Princeton","userId":"11074157683333558795"}},"outputId":"de7ab64d-ae77-4aa8-af38-8227c8a2dfe7"},"outputs":[{"output_type":"error","ename":"TclError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-124-19fc4f20ad0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Chat Bot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Chat Bot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2268\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"]}],"source":["import random\n","import tkinter as tk\n","from tkinter import *\n","\n","root=tk.Tk()\n","filename=\"Chat Bot\"\n","root.title(f\"Chat Bot\")\n","root.geometry('500x400')\n","root.resizable(False, False)\n","message=tk.StringVar()\n","\n","chat_win=Frame(root,bd=1,bg='white',width=50,height=8)\n","chat_win.place(x=6,y=6,height=300,width=488)\n","\n","textcon=tk.Text(chat_win,bd=1,bg='white',width=50,height=8)\n","textcon.pack(fill=\"both\",expand=True)\n","\n","mes_win=Entry(root,width=30,xscrollcommand=True,textvariable=message)\n","mes_win.place(x=6,y=310,height=60,width=380)\n","mes_win.focus()\n","\n","textcon.config(fg='black')\n","textcon.tag_config('usr',foreground='black')\n","textcon.insert(END,\"Bot: This is Sophie! Your Personal Assistant.\\n\\n\")\n","mssg=mes_win.get()\n","\n","exit_list = ['exit','break','quit','see you later','chat with you later','end the chat','bye','ok bye']\n","\n","def greet_res(text):\n","    text=text.lower()\n","    bot_greet=['hi','hello','hola','hey','howdy']\n","    usr_greet=['hi','hey','hello','hola','greetings','wassup','whats up']\n","    for word in text.split():\n","        if word in usr_greet:\n","            return random.choice(bot_greet)\n","\n","def send_msz(event=None):\n","    usr_input = message.get()\n","    usr_input = usr_input.lower()\n","    textcon.insert(END, f'You: {usr_input}'+'\\n','usr')\n","    if usr_input in exit_list:\n","        textcon.config(fg='black')\n","        textcon.insert(END,\"Bot: Ok bye! Chat with you later\\n\")\n","        return root.destroy()\n","    else:\n","        textcon.config(fg='black')\n","        if greet_res(usr_input) != None:\n","            lab=f\"Bot: {greet_res(usr_input)}\"+'\\n'\n","            textcon.insert(END,lab)\n","            mes_win.delete(0,END)\n","        else:\n","            lab = f\"Bot: {chatbot_response(usr_input)}\"+'\\n'\n","            textcon.insert(END,lab)\n","            mes_win.delete(0,END)\n","\n","button_send=Button(root,text='Send',bg='dark green',activebackground='grey',command=send_msz,width=12,height=5,font=('Arial'))\n","button_send.place(x=376,y=310,height=60,width=110)\n","root.bind('<Return>', send_msz,button_send)\n","root.mainloop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7RNxKxQd02I"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DUQKXbvd02J"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCfVGJ60d02J"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
